{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import gudhi as gd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gudhi.representations\n",
    "from datetime import timedelta\n",
    "from pandas.tseries.offsets import BDay\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from scipy.signal import periodogram\n",
    "from scipy.fftpack import fft, fftfreq, ifft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               DJIA  NASDAQ  Russel2000   SP500\n",
      "Date                                           \n",
      "1987-12-23  2005.64  331.48      120.80  253.16\n",
      "1987-12-24  1999.67  333.19      121.59  252.02\n",
      "1987-12-28  1942.97  325.60      119.00  245.57\n",
      "1987-12-29  1926.89  325.53      118.30  244.59\n",
      "1987-12-30  1950.10  329.70      119.50  247.86\n"
     ]
    }
   ],
   "source": [
    "colnames = ['Date','Open','High', 'Low','Close']\n",
    "\n",
    "DJIA = pd.read_csv('DJIA.csv', parse_dates = ['Date'], index_col= 'Date', names = colnames, header = 0, date_format = 'mixed')\n",
    "NASDAQ = pd.read_csv('NASDAQ.csv', parse_dates = ['Date'], index_col= 'Date', names = colnames, header = 0, date_format = 'mixed')\n",
    "Russel2000 = pd.read_csv('Russel2000.csv', parse_dates = ['Date'], index_col= 'Date', names = colnames, header = 0, date_format = 'mixed')\n",
    "SP500 = pd.read_csv('S&P500.csv', parse_dates = ['Date'], index_col= 'Date', names = colnames, header = 0, date_format = 'mixed')\n",
    "\n",
    "close = pd.concat([DJIA['Close'],NASDAQ['Close'],Russel2000['Close'],SP500['Close']], axis = 1)\n",
    "close.columns = ['DJIA', 'NASDAQ','Russel2000', 'SP500']\n",
    "close.sort_index(inplace = True)\n",
    "print(close.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2016-12-08    19614.81\n",
       "2016-12-07    19549.62\n",
       "2016-12-06    19251.78\n",
       "2016-12-05    19216.24\n",
       "2016-12-02    19170.42\n",
       "                ...   \n",
       "1987-12-30     1950.10\n",
       "1987-12-29     1926.89\n",
       "1987-12-28     1942.97\n",
       "1987-12-24     1999.67\n",
       "1987-12-23     2005.64\n",
       "Name: Close, Length: 7301, dtype: float64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DJIA['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DJIA          4592.335122\n",
       "NASDAQ        1307.776871\n",
       "Russel2000     310.422507\n",
       "SP500          515.946759\n",
       "dtype: float64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinanceTimeSeries:\n",
    "\n",
    "    def __init__(self,data):\n",
    "        if type(data)==pd.DataFrame:\n",
    "            self.time_series = data\n",
    "        else:\n",
    "            try:\n",
    "                self.time_series = pd.DataFrame(data)\n",
    "            except ValueError:\n",
    "                raise ValueError(\"Could not convert data to DataFrame\")\n",
    "        self.return_df = False\n",
    "        self.scaled = False\n",
    "        self.return_scaled = False\n",
    "        self.persistence_norms = pd.DataFrame()\n",
    "        self.persistence_computed = False\n",
    "        self.avg_PSD = pd.DataFrame()\n",
    "        self.PSD_filter_keep = None\n",
    "        self.PSD_freq_cut = None\n",
    "        self.Lp_norms_scaling = None\n",
    "        self.norms_std =pd.DataFrame()\n",
    "        self.std_filter_keep = None\n",
    "        self.std_freq_cut = None\n",
    "    \n",
    "    def copy(self):\n",
    "        fts = deepcopy(self)\n",
    "        return fts\n",
    "    \n",
    "    def log_return(self, inplace = False):\n",
    "\n",
    "        \"\"\"Compute the log return of self.time_series\n",
    "\n",
    "        Returns:\n",
    "            FinanceTimeSeries: (self.time_series : pd.DataFrame) log return if inplace == False, else modify self.time_series\n",
    "        \"\"\"\n",
    "\n",
    "        if self.return_df:\n",
    "            print(\"This is already a return DataFrame.\")\n",
    "        else:\n",
    "            if inplace:\n",
    "                fts = self\n",
    "            else:\n",
    "                fts = self.copy()\n",
    "\n",
    "            fts.time_series = np.log(fts.time_series.pct_change().dropna() +1)\n",
    "\n",
    "            fts.return_df = True\n",
    "\n",
    "            if not inplace:\n",
    "                return fts\n",
    "            \n",
    "    def scale(self, inplace = False):\n",
    "\n",
    "        \"\"\"Scaling of self.time_series with StandardScaler\n",
    "\n",
    "        Returns:\n",
    "            FinanceTimeSeries: (self.time_series : pd.DataFrame) scale if inplace == False, else modify self.time_series\n",
    "        \"\"\"\n",
    "\n",
    "        if self.scaled:\n",
    "            print(\"The DataFrame is already scaled.\")\n",
    "        else :\n",
    "            if inplace:\n",
    "                fts = self\n",
    "            else:\n",
    "                fts = self.copy()\n",
    "            \n",
    "            scaler = StandardScaler()\n",
    "            fts.time_series = pd.DataFrame(scaler.fit_transform(fts.time_series),\n",
    "                                           columns = fts.time_series.columns,\n",
    "                                             index = fts.time_series.index\n",
    "                                             )\n",
    "            \n",
    "            fts.scaled = True\n",
    "\n",
    "            if not inplace:\n",
    "                return fts\n",
    "            \n",
    "    def scale_log_return(self, inplace = False):\n",
    "\n",
    "        \"\"\"Compute log return then sclae with StandardScaler sel.time_series\n",
    "\n",
    "        Returns:\n",
    "            FinanceTimeSeries: (self.time_series : pd.DataFrame) computation of scaled log return if inplace == False, else modify self.time_series\n",
    "        \"\"\"\n",
    "\n",
    "        if self.return_scaled:\n",
    "            print(\"The DataFrame is already a scaled log_return.\")\n",
    "        else :\n",
    "            if inplace:\n",
    "                fts = self\n",
    "            else:\n",
    "                fts = self.copy()\n",
    "\n",
    "        fts.log_return(inplace = True)\n",
    "        fts.scale(inplace = True)\n",
    "\n",
    "        fts.return_scaled = True\n",
    "\n",
    "        if not inplace:\n",
    "            return fts\n",
    "        \n",
    "    def compute_persistence_norms_seq(self, window_size, p_norms, dimension, scaling = None, inplace = False):\n",
    "\n",
    "        \"\"\"Compute the sequence of Lp norms of persistence landscapes, each element of the sequence is computed on a window\n",
    "\n",
    "        Args:\n",
    "            window_size (int): size of the rolling window\n",
    "            p_norms (list): list of integers p for which the Lp norm is computed\n",
    "            dimension (int): degree of the persistence module for which norms are computed\n",
    "            scaling (sklearn.preprocessing._data): choice of scaler to scale the norm\n",
    "\n",
    "        Returns:\n",
    "            FinanceTimeSeries: (self.persistence_norms: pd.Dataframe) computation of Lp persistence norms if inplace == False, else modify self.persistence_norms\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.return_scaled:\n",
    "            print(\"The TimeSeries is not a scaled log_return.\")\n",
    "        else:\n",
    "            if inplace:\n",
    "                fts = self\n",
    "            else:\n",
    "                fts = self.copy()\n",
    "\n",
    "            diagrams = {}\n",
    "            for t in fts.time_series.index[window_size+1:]:\n",
    "                points = fts.time_series[t-BDay(window_size): t].to_numpy()\n",
    "                skeleton = gd.RipsComplex(points = points)\n",
    "                Rips_tree = skeleton.create_simplex_tree(max_dimension = dimension+1)\n",
    "                dgr = Rips_tree.persistence()\n",
    "\n",
    "                LS = gd.representations.Landscape()\n",
    "                L = LS.fit_transform([Rips_tree.persistence_intervals_in_dimension(dimension)])\n",
    "                \n",
    "                norms = [np.linalg.norm(L[0], ord = p) for p in p_norms]\n",
    "                diagrams[t] = norms\n",
    "\n",
    "            Norms = pd.DataFrame(diagrams).transpose()\n",
    "            Norms.columns = [f\"L{p}_norm\" for p in p_norms]\n",
    "\n",
    "            if scaling is not None:\n",
    "                scaler = scaling\n",
    "                Norms = pd.DataFrame(scaler.fit_transform(Norms),\n",
    "                                     columns = Norms.columns,\n",
    "                                     index = Norms.index\n",
    "                                     )\n",
    "\n",
    "            fts.persistence_norms = Norms\n",
    "            fts.persistence_computed = True\n",
    "            fts.Lp_norms_scaling = scaling\n",
    "\n",
    "            if not inplace:\n",
    "                return fts\n",
    "\n",
    "    def avgPSD(self , window_size, freq_cut = None, filter_keep = None, inplace = False):\n",
    "\n",
    "        \"\"\"Compute the sequence of the Lp norms' average power spectral density at high or low frequencies, each element of the sequence is computed on a window\n",
    "\n",
    "        Args:\n",
    "            window_size (int): size of the rolling window on which each persistence norm is computed\n",
    "            freq_cut (float): threshold for the frequence cut\n",
    "            filter_keep (str): choice of filter; 'low' to keep low frequencies, 'high' to keep high frequencies, None to keep all frequencies\n",
    "\n",
    "        Returns:\n",
    "            FinanceTimeSeries: (self.avg_PSD: pd.Dataframe) computation of filtered average spectral power density if inplace == False, else modify self.avg_PSD\n",
    "        \"\"\"\n",
    "\n",
    "        if inplace:\n",
    "            fts = self\n",
    "        else:\n",
    "            fts = self.copy()\n",
    "\n",
    "        \n",
    "        def avgPSD_total(data, freq_cut = None, filter_keep = None):\n",
    "\n",
    "\n",
    "            if filter_keep is not None and freq_cut is None:\n",
    "                print(\"No frequence cut provided.\")\n",
    "            else:\n",
    "                (f,S)= periodogram(data,scaling = 'density')\n",
    "                df_freq = pd.DataFrame((f,S), index = ['frequency','PSD']).transpose()\n",
    "\n",
    "                if filter_keep == 'low':\n",
    "                    return df_freq[df_freq['frequency'] < freq_cut]['PSD'].mean()\n",
    "                elif filter_keep == 'high':\n",
    "                    return df_freq[df_freq['frequency'] > freq_cut]['PSD'].mean()\n",
    "                else:\n",
    "                    return df_freq['PSD'].mean()\n",
    "        \n",
    "        fts.avg_PSD = fts.persistence_norms.rolling(window_size).agg(\n",
    "            lambda x : avgPSD_total(x, freq_cut, filter_keep)\n",
    "            )\n",
    "        fts.avg_PSD.dropna(inplace = True)\n",
    "        fts.avg_PSD.columns = ['PSD_'+ col_name for col_name in fts.persistence_norms.columns]\n",
    "        \n",
    "        fts.PSD_filter_keep = filter_keep\n",
    "        fts.PSD_freq_cut = freq_cut\n",
    "\n",
    "        if filter_keep == None:\n",
    "            print(\"No filter selected.\")\n",
    "\n",
    "        if not inplace:\n",
    "            return fts\n",
    "    \n",
    "    def std_freq_filter(self, window_size, freq_cut = None, filter_keep = None, spacing = 1, inplace = False):\n",
    "\n",
    "        \"\"\"Compute the sequence of the Lp norms' standard deviation, each element of the sequence is computed on a window\n",
    "\n",
    "        Args:\n",
    "            window_size (int): size of the rolling window on which each persistence norm is computed\n",
    "            freq_cut (float): threshold for the frequence cut\n",
    "            filter_keep (str): choice of filter; 'low' to keep low frequencies, 'high' to keep high frequencies, None to keep all frequencies\n",
    "\n",
    "        Returns:\n",
    "            FinanceTimeSeries: (self.avg_PSD: pd.Dataframe) computation of standard deviation if inplace == False, else modify self.avg_PSD\n",
    "        \"\"\"\n",
    "\n",
    "        if inplace:\n",
    "            fts = self\n",
    "        else:\n",
    "            fts = self.copy()\n",
    "        \n",
    "        def std_norms_total(data ,freq_cut = None, filter_keep = None, spacing = 1):\n",
    "            if filter_keep is not None and freq_cut is None:\n",
    "                print(\"No frequence cut provided.\")\n",
    "            else:\n",
    "                norms_fft = fft(data.values)\n",
    "                norms_freq = fftfreq(len(norms_fft),spacing)\n",
    "                \n",
    "                if filter_keep == 'low':\n",
    "                    norms_fft[np.abs(norms_freq) > freq_cut] = 0\n",
    "                    norms_low = np.real(ifft(norms_fft))\n",
    "                    return norms_low.std()\n",
    "                elif filter_keep == 'high':\n",
    "                    norms_fft[np.abs(norms_freq) < freq_cut] = 0\n",
    "                    norms_high = np.real(ifft(norms_fft))\n",
    "                    return norms_high.std()\n",
    "                else:\n",
    "                    return data.std()\n",
    "        \n",
    "        fts.norms_std = fts.persistence_norms.rolling(window_size).agg(\n",
    "            lambda x : std_norms_total(x, freq_cut, filter_keep, spacing)\n",
    "            )\n",
    "        fts.norms_std.dropna(inplace = True)\n",
    "        fts.norms_std.columns = ['std_'+ col_name for col_name in fts.persistence_norms.columns]\n",
    "\n",
    "        fts.std_freq_cut = freq_cut\n",
    "        fts.std_filter_keep = filter_keep\n",
    "\n",
    "        if filter_keep == None:\n",
    "            print(\"No filter selected.\")\n",
    "\n",
    "        if not inplace:\n",
    "            return fts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "fts = FinanceTimeSeries(close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "fts.scale_log_return(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1_norm</th>\n",
       "      <th>L2_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1988-03-09</th>\n",
       "      <td>0.084502</td>\n",
       "      <td>0.143662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988-03-10</th>\n",
       "      <td>0.084502</td>\n",
       "      <td>0.143662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988-03-11</th>\n",
       "      <td>0.091862</td>\n",
       "      <td>0.147609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988-03-14</th>\n",
       "      <td>0.081787</td>\n",
       "      <td>0.143001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988-03-15</th>\n",
       "      <td>0.081787</td>\n",
       "      <td>0.143001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-02</th>\n",
       "      <td>0.050529</td>\n",
       "      <td>0.073259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-05</th>\n",
       "      <td>0.018433</td>\n",
       "      <td>0.044178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-06</th>\n",
       "      <td>0.044867</td>\n",
       "      <td>0.070679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-07</th>\n",
       "      <td>0.047041</td>\n",
       "      <td>0.072400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-08</th>\n",
       "      <td>0.047041</td>\n",
       "      <td>0.072400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7249 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             L1_norm   L2_norm\n",
       "1988-03-09  0.084502  0.143662\n",
       "1988-03-10  0.084502  0.143662\n",
       "1988-03-11  0.091862  0.147609\n",
       "1988-03-14  0.081787  0.143001\n",
       "1988-03-15  0.081787  0.143001\n",
       "...              ...       ...\n",
       "2016-12-02  0.050529  0.073259\n",
       "2016-12-05  0.018433  0.044178\n",
       "2016-12-06  0.044867  0.070679\n",
       "2016-12-07  0.047041  0.072400\n",
       "2016-12-08  0.047041  0.072400\n",
       "\n",
       "[7249 rows x 2 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fts.compute_persistence_norms_seq(50,[1,2], 1, scaling = MinMaxScaler(), inplace = True)\n",
    "fts.persistence_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PSD_L1_norm</th>\n",
       "      <th>PSD_L2_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1989-03-03</th>\n",
       "      <td>0.004125</td>\n",
       "      <td>0.008258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989-03-06</th>\n",
       "      <td>0.004118</td>\n",
       "      <td>0.008239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989-03-07</th>\n",
       "      <td>0.004110</td>\n",
       "      <td>0.008220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989-03-08</th>\n",
       "      <td>0.004098</td>\n",
       "      <td>0.008196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989-03-09</th>\n",
       "      <td>0.004092</td>\n",
       "      <td>0.008178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-02</th>\n",
       "      <td>0.005548</td>\n",
       "      <td>0.008378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-05</th>\n",
       "      <td>0.005187</td>\n",
       "      <td>0.007913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-06</th>\n",
       "      <td>0.004805</td>\n",
       "      <td>0.007421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-07</th>\n",
       "      <td>0.004508</td>\n",
       "      <td>0.006970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-08</th>\n",
       "      <td>0.004208</td>\n",
       "      <td>0.006515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            PSD_L1_norm  PSD_L2_norm\n",
       "1989-03-03     0.004125     0.008258\n",
       "1989-03-06     0.004118     0.008239\n",
       "1989-03-07     0.004110     0.008220\n",
       "1989-03-08     0.004098     0.008196\n",
       "1989-03-09     0.004092     0.008178\n",
       "...                 ...          ...\n",
       "2016-12-02     0.005548     0.008378\n",
       "2016-12-05     0.005187     0.007913\n",
       "2016-12-06     0.004805     0.007421\n",
       "2016-12-07     0.004508     0.006970\n",
       "2016-12-08     0.004208     0.006515\n",
       "\n",
       "[7000 rows x 2 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fts.avgPSD(250,freq_cut = 1, filter_keep = 'low').avg_PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>std_L1_norm</th>\n",
       "      <th>std_L2_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1989-03-03</th>\n",
       "      <td>0.043278</td>\n",
       "      <td>0.061696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989-03-06</th>\n",
       "      <td>0.043237</td>\n",
       "      <td>0.061614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989-03-07</th>\n",
       "      <td>0.043192</td>\n",
       "      <td>0.061538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989-03-08</th>\n",
       "      <td>0.043145</td>\n",
       "      <td>0.061469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989-03-09</th>\n",
       "      <td>0.043107</td>\n",
       "      <td>0.061410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-02</th>\n",
       "      <td>0.049295</td>\n",
       "      <td>0.061257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-05</th>\n",
       "      <td>0.046990</td>\n",
       "      <td>0.058726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-06</th>\n",
       "      <td>0.045075</td>\n",
       "      <td>0.056498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-07</th>\n",
       "      <td>0.043579</td>\n",
       "      <td>0.054619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-08</th>\n",
       "      <td>0.042374</td>\n",
       "      <td>0.053214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            std_L1_norm  std_L2_norm\n",
       "1989-03-03     0.043278     0.061696\n",
       "1989-03-06     0.043237     0.061614\n",
       "1989-03-07     0.043192     0.061538\n",
       "1989-03-08     0.043145     0.061469\n",
       "1989-03-09     0.043107     0.061410\n",
       "...                 ...          ...\n",
       "2016-12-02     0.049295     0.061257\n",
       "2016-12-05     0.046990     0.058726\n",
       "2016-12-06     0.045075     0.056498\n",
       "2016-12-07     0.043579     0.054619\n",
       "2016-12-08     0.042374     0.053214\n",
       "\n",
       "[7000 rows x 2 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fts.std_freq_filter(250, freq_cut = 10, filter_keep = 'low', spacing = 0.01).norms_std"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gudhi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
