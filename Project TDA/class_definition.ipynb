{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import gudhi as gd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gudhi.representations\n",
    "from datetime import timedelta\n",
    "from pandas.tseries.offsets import BDay\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from scipy.signal import periodogram\n",
    "from scipy.fftpack import fft, fftfreq, ifft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               DJIA  NASDAQ  Russel2000   SP500\n",
      "Date                                           \n",
      "1987-12-23  2005.64  331.48      120.80  253.16\n",
      "1987-12-24  1999.67  333.19      121.59  252.02\n",
      "1987-12-28  1942.97  325.60      119.00  245.57\n",
      "1987-12-29  1926.89  325.53      118.30  244.59\n",
      "1987-12-30  1950.10  329.70      119.50  247.86\n"
     ]
    }
   ],
   "source": [
    "colnames = ['Date','Open','High', 'Low','Close']\n",
    "\n",
    "DJIA = pd.read_csv('DJIA.csv', parse_dates = ['Date'], index_col= 'Date', names = colnames, header = 0, date_format = 'mixed')\n",
    "NASDAQ = pd.read_csv('NASDAQ.csv', parse_dates = ['Date'], index_col= 'Date', names = colnames, header = 0, date_format = 'mixed')\n",
    "Russel2000 = pd.read_csv('Russel2000.csv', parse_dates = ['Date'], index_col= 'Date', names = colnames, header = 0, date_format = 'mixed')\n",
    "SP500 = pd.read_csv('S&P500.csv', parse_dates = ['Date'], index_col= 'Date', names = colnames, header = 0, date_format = 'mixed')\n",
    "\n",
    "close = pd.concat([DJIA['Close'],NASDAQ['Close'],Russel2000['Close'],SP500['Close']], axis = 1)\n",
    "close.columns = ['DJIA', 'NASDAQ','Russel2000', 'SP500']\n",
    "close.sort_index(inplace = True)\n",
    "print(close.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinanceTimeSeries:\n",
    "\n",
    "    def __init__(self,data):\n",
    "        self.time_series = data\n",
    "        self.return_df = False\n",
    "        self.scaled = False\n",
    "        self.return_scaled = False\n",
    "        self.persistence_norms = pd.DataFrame()\n",
    "        self.persistence_computed = False\n",
    "        self.avg_PSD = pd.DataFrame()\n",
    "        self.PSD_filter_keep = None\n",
    "        self.PSD_freq_cut = None\n",
    "    \n",
    "    def copy(self):\n",
    "        df = deepcopy(self)\n",
    "        return df\n",
    "    \n",
    "    def log_return(self, inplace = False):\n",
    "        if self.return_df:\n",
    "            print(\"This is already a return DataFrame.\")\n",
    "        else:\n",
    "            if inplace:\n",
    "                df = self\n",
    "            else:\n",
    "                df = self.copy()\n",
    "\n",
    "            df.time_series = np.log(df.time_series.pct_change().dropna() +1)\n",
    "\n",
    "            df.return_df = True\n",
    "\n",
    "            if not inplace:\n",
    "                return df\n",
    "            \n",
    "    def scale(self, inplace = False):\n",
    "        if self.scaled:\n",
    "            print(\"The DataFrame is already scaled.\")\n",
    "        else :\n",
    "            if inplace:\n",
    "                df = self\n",
    "            else:\n",
    "                df = self.copy()\n",
    "            \n",
    "            scaler = StandardScaler()\n",
    "            df.time_series = pd.DataFrame(scaler.fit_transform(df.time_series),columns = df.time_series.columns, index = df.time_series.index)\n",
    "            \n",
    "            df.scaled = True\n",
    "\n",
    "            if not inplace:\n",
    "                return df\n",
    "            \n",
    "    def scale_log_return(self, inplace = False):\n",
    "        if self.return_scaled:\n",
    "            print(\"The DataFrame is already a scaled log_return.\")\n",
    "        else :\n",
    "            if inplace:\n",
    "                df = self\n",
    "            else:\n",
    "                df = self.copy()\n",
    "\n",
    "        df.log_return(inplace = True)\n",
    "        df.scale(inplace = True)\n",
    "\n",
    "        df.return_scaled = True\n",
    "\n",
    "        if not inplace:\n",
    "            return df\n",
    "        \n",
    "    def compute_persistence_norms_seq(self, window_size, p_norms, dimension, scaling = None):\n",
    "        if not self.return_scaled:\n",
    "            print(\"The TimeSeries is not a scaled log_return.\")\n",
    "        else:\n",
    "            diagrams = {}\n",
    "            for t in self.time_series.index[window_size+1:]:\n",
    "                points = self.time_series[t-BDay(window_size): t].to_numpy()\n",
    "                skeleton = gd.RipsComplex(points = points)\n",
    "                Rips_tree = skeleton.create_simplex_tree(max_dimension = dimension+1)\n",
    "                dgr = Rips_tree.persistence()\n",
    "\n",
    "                LS = gd.representations.Landscape()\n",
    "                L = LS.fit_transform([Rips_tree.persistence_intervals_in_dimension(dimension)])\n",
    "                \n",
    "                norms = [np.linalg.norm(L[0], ord = p) for p in p_norms]\n",
    "\n",
    "                diagrams[t] = norms\n",
    "            Norms = pd.DataFrame(diagrams).transpose()\n",
    "            Norms.columns = [f\"L{p}_norm\" for p in p_norms]\n",
    "\n",
    "            if scaling is not None:\n",
    "                scaler = scaling\n",
    "                Norms = pd.DataFrame(scaler.fit_transform(Norms),columns = Norms.columns, index = Norms.index)\n",
    "\n",
    "            self.persistence_norms = Norms\n",
    "            self.persistence_computed = True\n",
    "\n",
    "    def avgPSD(self , window_size, freq_cut = None, filter_keep = None):\n",
    "\n",
    "        \n",
    "        def avgPSD_total(data, freq_cut = None, filter_keep = None):\n",
    "            if filter_keep is not None and freq_cut is None:\n",
    "                print(\"No frequence cut provided.\")\n",
    "            else:\n",
    "                (f,S)= periodogram(data,scaling = 'density')\n",
    "                df_freq = pd.DataFrame((f,S), index = ['frequency','PSD']).transpose()\n",
    "                if filter_keep == 'low':\n",
    "                    return df_freq[df_freq['frequency'] < freq_cut]['PSD'].mean()\n",
    "                elif filter_keep == 'high':\n",
    "                    return df_freq[df_freq['frequency'] > freq_cut]['PSD'].mean()\n",
    "                else:\n",
    "                    return df_freq['PSD'].mean()\n",
    "        \n",
    "        self.avg_PSD = self.persistence_norms.rolling(window_size).agg(lambda x : avgPSD_total(x, freq_cut, filter_keep))\n",
    "        self.avg_PSD.dropna(inplace = True)\n",
    "        self.avg_PSD.columns = ['PSD_'+ col_name for col_name in self.persistence_norms.columns]\n",
    "        self.PSD_filter_keep = filter_keep\n",
    "        self.PSD_freq_cut = freq_cut\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "fts = FinanceTimeSeries(close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "fts.scale_log_return(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             L1_norm   L2_norm\n",
      "1988-03-09  0.084502  0.143662\n",
      "1988-03-10  0.084502  0.143662\n",
      "1988-03-11  0.091862  0.147609\n",
      "1988-03-14  0.081787  0.143001\n",
      "1988-03-15  0.081787  0.143001\n",
      "...              ...       ...\n",
      "2016-12-02  0.050529  0.073259\n",
      "2016-12-05  0.018433  0.044178\n",
      "2016-12-06  0.044867  0.070679\n",
      "2016-12-07  0.047041  0.072400\n",
      "2016-12-08  0.047041  0.072400\n",
      "\n",
      "[7249 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "fts.compute_persistence_norms_seq(50,[1,2], 1, scaling = MinMaxScaler())\n",
    "print(fts.persistence_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            PSD_L1_norm  PSD_L2_norm\n",
      "1989-03-03     0.004125     0.008258\n",
      "1989-03-06     0.004118     0.008239\n",
      "1989-03-07     0.004110     0.008220\n",
      "1989-03-08     0.004098     0.008196\n",
      "1989-03-09     0.004092     0.008178\n",
      "...                 ...          ...\n",
      "2016-12-02     0.005548     0.008378\n",
      "2016-12-05     0.005187     0.007913\n",
      "2016-12-06     0.004805     0.007421\n",
      "2016-12-07     0.004508     0.006970\n",
      "2016-12-08     0.004208     0.006515\n",
      "\n",
      "[7000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "fts.avgPSD(250,freq_cut = 1, filter_keep = 'low')\n",
    "print(fts.avg_PSD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                DJIA    NASDAQ  Russel2000     SP500\n",
      "Date                                                \n",
      "1987-12-24 -0.307443  0.334678    0.480984 -0.430986\n",
      "1987-12-28 -2.714342 -1.646153   -1.700630 -2.348739\n",
      "1987-12-29 -0.804945 -0.042002   -0.484861 -0.384903\n",
      "1987-12-30  1.088561  0.867545    0.758970  1.162635\n",
      "1987-12-31 -0.570217  0.137029    0.570491 -0.309064\n",
      "...              ...       ...         ...       ...\n",
      "2016-12-02 -0.133845  0.033835    0.000635  0.008772\n",
      "2016-12-05  0.193695  0.681368    1.354759  0.493060\n",
      "2016-12-06  0.143330  0.291513    0.834322  0.278175\n",
      "2016-12-07  1.403991  0.769186    0.651823  1.144416\n",
      "2016-12-08  0.281609  0.279899    1.210140  0.166406\n",
      "\n",
      "[7300 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(fts.scale_log_return().time_series)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gudhi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
